[SPARK_HISTORY]
api_base_url = http://localhost:18080/api/v1

[CRAWLER]
# Time between pulling of new completed runs from Spark History
sleep_seconds = 10

# When processing a particular run causes an exception
# (e.g. missing critical metadata, external services errors, etc.)
# the error message is logged into err_index.
# The setting skip_exceptions defines whether to terminate Crawler process
# or skip the malformed run and continue.
# Skipping is recommended for production deployment,
# while the opposite is recommended for debugging.
skip_exceptions = False

[SPOT_ELASTICSEARCH]
elasticsearch_url = http://localhost:9200
raw_index = spot_raw_mycluster_1
agg_index = spot_agg_mycluster_1
err_index = spot_err_mycluster_1
# auth types for Elasticsearch currently supported:
#   default - username and password
#   AWS Cognito - USER_PASSWORD_AUTH via SRP
auth_type = default
username =
password =
# Required if using AWS Cognito
#aws_account_id =
#user_pool_id =
#identity_pool_id =
#cognito_region =
#elasticsearch_region =
#client_id =
#client_secret =
#elasticsearch_role_name =

[MISC]
output_dir = output
log_level = debug

[MENAS]
# Menas provides additional metadata for Enceladus jobs (OPTIONAL)
# api_base_url = https://localhost:8080/menas/api
# Provide a path to a CA bundle for Menas HTTPS verification, if required
# menas_ssl_path =
# username = user
# password = changeme
